develop a hand gesture recognition model that can accurate identify and classify different hand gestures
from image or video data,enabling intuitive human-computer interaction and gesture-based control systems.


import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
# Function to load images and labels from the dataset
def load_data(dataset_path):
    images = []
    labels = []
    image_size = (64, 64)  # Define the image size to which each image will be resized

    # Iterate over each gesture folder in the dataset
    for gesture in os.listdir(dataset_path):
        gesture_path = os.path.join(dataset_path, gesture)
        
        # Skip if it's not a directory
        if not os.path.isdir(gesture_path):
            continue
        
        # Load each image in the gesture folder
        for img_name in os.listdir(gesture_path):
            img_path = os.path.join(gesture_path, img_name)
            img = cv2.imread(img_path)
            
            # Check if the image was loaded successfully
            if img is None:
                print(f"Warning: Unable to read image {img_path}. It may not exist or is corrupted.")
                continue
            
            # Resize image and append it to the list
            img = cv2.resize(img, image_size)
            images.append(img)
            labels.append(int(gesture))  # Assuming folders are named 0, 1, 2, ..., num_classes-1
    
    print(f"Total images loaded: {len(images)}")
    print(f"Total labels loaded: {len(labels)}")
    return np.array(images), np.array(labels)

# Set path to your dataset directory
dataset_path = r'C:\Users\Rishav Roshan\Downloads\leapGestRecog'

# Load images and labels
images, labels = load_data(dataset_path)

# Check if images and labels are loaded
if images.size == 0 or labels.size == 0:
    raise ValueError("No images or labels loaded. Please check your dataset.")

# Preprocess the images and labels
images = images.astype('float32') / 255.0  # Normalize pixel values
num_classes = len(set(labels))  # Update this based on your dataset's classes
labels = np.eye(num_classes)[labels]  # One-hot encoding

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
# CNN Model for Hand Gesture Recognition
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPooling2D((2, 2)),
    Dropout(0.2),
    
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.2),
    
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.2),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])
# Compiling the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True
)

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
# Training the model
history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    validation_data=(X_test, y_test),
    epochs=30,
    callbacks=[early_stopping]
)
# Evaluating the model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)
print(f"Test accuracy: {test_accuracy * 100:.2f}%")
# Ploting training and validation accuracy and loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()
# Saving the trained model
model.save("hand_gesture_recognition_model.h5")
print("Model saved as 'hand_gesture_recognition_model.h5'")
